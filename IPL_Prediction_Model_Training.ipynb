{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriya-cybertech/ipl-match-prediction-ml/blob/main/IPL_Prediction_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXBU8kPxT1Al"
      },
      "source": [
        "# IPL 1st Inning Score Prediction using Machine Learning\n",
        "The Dataset contains ball by ball information of the matches played between IPL Teams of **Season 1 to 10**, i.e. from 2008 to 2017.<br/>\n",
        "This Machine Learning model adapts a Regression Appoach to predict the score of the First Inning of an IPL Match.<br/>\n",
        "The Dataset can be downloaded from Kaggle from [here](https://www.kaggle.com/yuvrajdagur/ipl-dataset-season-2008-to-2017).<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deQNulMrT_fi"
      },
      "source": [
        "# Import Necessary Libraries\n",
        "and Mounting GDrive for importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0AuT36T3Eds"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8WZBYt3wT3t"
      },
      "source": [
        "Mount your Google Drive and save the dataset in the Drive name \"data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHAMX3Kh3LfY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Mounting GDrive and importing dataset\n",
        "data = pd.read_csv('/content/ipl_colab.csv')\n",
        "print(f\"Dataset successfully Imported of Shape : {data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CSd3bM4U8S"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XobBp7D74Pb0"
      },
      "outputs": [],
      "source": [
        "# First 5 Columns Data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl5XPiHq4aG0"
      },
      "outputs": [],
      "source": [
        "# Describing Numerical Values of the Dataset\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPpXimQR4gCc"
      },
      "outputs": [],
      "source": [
        "# Information (not-null count and data type) About Each Column\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWmwXKCK4huV"
      },
      "outputs": [],
      "source": [
        "# Number of Unique Values in each column\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WvhLdlTaEdt"
      },
      "outputs": [],
      "source": [
        "# Datatypes of all Columns\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxFkLRRI8RTi"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0bwc9vT-7Th"
      },
      "source": [
        "#### Removing Irrelevant Data colunms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb-QjD1a6tRs"
      },
      "outputs": [],
      "source": [
        "# Names of all columns\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcBf3QuOgzZY"
      },
      "source": [
        "Here, we can see that columns _['mid', 'date', 'venue', 'batsman', 'bowler', 'striker', 'non-striker']_ won't provide any relevant information for our model to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o4-CkhP8W2f"
      },
      "outputs": [],
      "source": [
        "irrelevant = ['mid', 'date', 'venue','batsman', 'bowler', 'striker', 'non-striker']\n",
        "print(f'Before Removing Irrelevant Columns : {data.shape}')\n",
        "data = data.drop(irrelevant, axis=1) # Drop Irrelevant Columns\n",
        "print(f'After Removing Irrelevant Columns : {data.shape}')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h2boQJQ-iQp"
      },
      "source": [
        "#### Keeping only Consistent Teams\n",
        "(teams that never change even in current season)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1LFaSI_8rF7"
      },
      "outputs": [],
      "source": [
        "# Define Consistent Teams\n",
        "const_teams = ['Kolkata Knight Riders', 'Chennai Super Kings', 'Rajasthan Royals',\n",
        "              'Mumbai Indians', 'Kings XI Punjab', 'Royal Challengers Bangalore',\n",
        "              'Delhi Daredevils', 'Sunrisers Hyderabad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6r3wXug-z5r"
      },
      "outputs": [],
      "source": [
        "print(f'Before Removing Inconsistent Teams : {data.shape}')\n",
        "data = data[(data['batting_team'].isin(const_teams)) & (data['bowling_team'].isin(const_teams))]\n",
        "print(f'After Removing Irrelevant Columns : {data.shape}')\n",
        "print(f\"Consistent Teams : \\n{data['batting_team'].unique()}\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeyQw7ipA1-r"
      },
      "source": [
        "#### Remove First 5 Overs of every match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6zO88dj_5Q7"
      },
      "outputs": [],
      "source": [
        "print(f'Before Removing Overs : {data.shape}')\n",
        "data = data[data['overs'] >= 5.0]\n",
        "print(f'After Removing Overs : {data.shape}')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaD8s97SnlnO"
      },
      "source": [
        "Plotting a Correlation Matrix of current data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDV9JNrZkvZ1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_data = data.select_dtypes(include=[\"number\"])\n",
        "\n",
        "# Compute correlation\n",
        "corr_matrix = numeric_data.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjtN9yMEmT0"
      },
      "source": [
        "# Data Preprocessing and Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGhNAvUxiy2p"
      },
      "source": [
        "#### Performing Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw2DBRSAB478"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "le = LabelEncoder()\n",
        "for col in ['batting_team', 'bowling_team']:\n",
        "  data[col] = le.fit_transform(data[col])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOGcIT_kjBbp"
      },
      "source": [
        "#### Performing One Hot Encoding and Column Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTBquJ09Fqpr"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "columnTransformer = ColumnTransformer([('encoder',\n",
        "                                        OneHotEncoder(),\n",
        "                                        [0, 1])],\n",
        "                                      remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHBT1Y68GcJn"
      },
      "outputs": [],
      "source": [
        "data = np.array(columnTransformer.fit_transform(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtvG6fLUjlPV"
      },
      "source": [
        "Save the Numpy Array in a new DataFrame with transformed columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQavBDKHGia1"
      },
      "outputs": [],
      "source": [
        "cols = ['batting_team_Chennai Super Kings', 'batting_team_Delhi Daredevils', 'batting_team_Kings XI Punjab',\n",
        "              'batting_team_Kolkata Knight Riders', 'batting_team_Mumbai Indians', 'batting_team_Rajasthan Royals',\n",
        "              'batting_team_Royal Challengers Bangalore', 'batting_team_Sunrisers Hyderabad',\n",
        "              'bowling_team_Chennai Super Kings', 'bowling_team_Delhi Daredevils', 'bowling_team_Kings XI Punjab',\n",
        "              'bowling_team_Kolkata Knight Riders', 'bowling_team_Mumbai Indians', 'bowling_team_Rajasthan Royals',\n",
        "              'bowling_team_Royal Challengers Bangalore', 'bowling_team_Sunrisers Hyderabad', 'runs', 'wickets', 'overs',\n",
        "       'runs_last_5', 'wickets_last_5', 'total']\n",
        "df = pd.DataFrame(data, columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M77XEk1VGjxo"
      },
      "outputs": [],
      "source": [
        "# Visualize Encoded Data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6kAENbRH7zF"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_zfjKeoH-5C"
      },
      "source": [
        "## Prepare Train and Test Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLK1yUvnGuDw"
      },
      "outputs": [],
      "source": [
        "features = df.drop(['total'], axis=1)\n",
        "labels = df['total']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR7cmz0tIhZW"
      },
      "outputs": [],
      "source": [
        "# Perform 80 : 20 Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.20, shuffle=True)\n",
        "print(f\"Training Set : {train_features.shape}\\nTesting Set : {test_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5ZhNp2EJ37b"
      },
      "source": [
        "## Model Algorithms\n",
        "Training and Testing on different Machine Learning Algorithms for the best algorithm to choose from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPgXWd3rKTnA"
      },
      "outputs": [],
      "source": [
        "# Keeping track of model perfomances\n",
        "models = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7HfUM1mKK2u"
      },
      "source": [
        "#### 1. Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X6OA45yJx0P"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree = DecisionTreeRegressor()\n",
        "# Train Model\n",
        "tree.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_kaCtenKiME"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "train_score_tree = str(tree.score(train_features, train_labels) * 100)\n",
        "test_score_tree = str(tree.score(test_features, test_labels) * 100)\n",
        "print(f'Train Score : {train_score_tree[:5]}%\\nTest Score : {test_score_tree[:5]}%')\n",
        "models[\"tree\"] = test_score_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPNUcmG0TwoK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse\n",
        "print(\"---- Decision Tree Regressor - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, tree.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, tree.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, tree.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F9fVUPuMwX0"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvNDa8MGdYYs"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "# Train Model\n",
        "linreg.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHOQcP-PQGYq"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "train_score_linreg = str(linreg.score(train_features, train_labels) * 100)\n",
        "test_score_linreg = str(linreg.score(test_features, test_labels) * 100)\n",
        "print(f'Train Score : {train_score_linreg[:5]}%\\nTest Score : {test_score_linreg[:5]}%')\n",
        "models[\"linreg\"] = test_score_linreg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVSzI12HRnnF"
      },
      "outputs": [],
      "source": [
        "print(\"---- Linear Regression - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, linreg.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, linreg.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, linreg.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPjZxiqnT3NC"
      },
      "source": [
        "#### Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub06meKxTlZh"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest = RandomForestRegressor()\n",
        "# Train Model\n",
        "forest.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3o7ax7BUOke"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "train_score_forest = str(forest.score(train_features, train_labels)*100)\n",
        "test_score_forest = str(forest.score(test_features, test_labels)*100)\n",
        "print(f'Train Score : {train_score_forest[:5]}%\\nTest Score : {test_score_forest[:5]}%')\n",
        "models[\"forest\"] = test_score_forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r82lD-fkebkn"
      },
      "outputs": [],
      "source": [
        "print(\"---- Random Forest Regression - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, forest.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, forest.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, forest.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ4gOn5nd_31"
      },
      "source": [
        "#### Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM5UDCyAeHcS"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "lasso = LassoCV()\n",
        "# Train Model\n",
        "lasso.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMBloU5SemTJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "train_score_lasso = str(lasso.score(train_features, train_labels)*100)\n",
        "test_score_lasso = str(lasso.score(test_features, test_labels)*100)\n",
        "print(f'Train Score : {train_score_lasso[:5]}%\\nTest Score : {test_score_lasso[:5]}%')\n",
        "models[\"lasso\"] = test_score_lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgQY888hej2W"
      },
      "outputs": [],
      "source": [
        "print(\"---- Lasso Regression - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, lasso.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, lasso.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, lasso.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64qH8gtlev5U"
      },
      "source": [
        "#### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzJJ9DUUezZj"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "svm = SVR()\n",
        "# Train Model\n",
        "svm.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqLSvMIce_Pt"
      },
      "outputs": [],
      "source": [
        "train_score_svm = str(svm.score(train_features, train_labels)*100)\n",
        "test_score_svm = str(svm.score(test_features, test_labels)*100)\n",
        "print(f'Train Score : {train_score_svm[:5]}%\\nTest Score : {test_score_svm[:5]}%')\n",
        "models[\"svm\"] = test_score_svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fSWYF30jxLr"
      },
      "outputs": [],
      "source": [
        "print(\"---- Support Vector Regression - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, svm.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, svm.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, svm.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRroeuZElfea"
      },
      "source": [
        "#### Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMQL5K7EkAuB"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "neural_net = MLPRegressor(activation='logistic', max_iter=500)\n",
        "# Train Model\n",
        "neural_net.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlSAZ_4skUDj"
      },
      "outputs": [],
      "source": [
        "train_score_neural_net = str(neural_net.score(train_features, train_labels)*100)\n",
        "test_score_neural_net = str(neural_net.score(test_features, test_labels)*100)\n",
        "print(f'Train Score : {train_score_neural_net[:5]}%\\nTest Score : {test_score_neural_net[:5]}%')\n",
        "models[\"neural_net\"] = test_score_neural_net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xhaNnp-kRkG"
      },
      "outputs": [],
      "source": [
        "print(\"---- Neural Networks Regression - Model Evaluation ----\")\n",
        "print(\"Mean Absolute Error (MAE): {}\".format(mae(test_labels, neural_net.predict(test_features))))\n",
        "print(\"Mean Squared Error (MSE): {}\".format(mse(test_labels, neural_net.predict(test_features))))\n",
        "print(\"Root Mean Squared Error (RMSE): {}\".format(np.sqrt(mse(test_labels, neural_net.predict(test_features)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iUiJYZzpF0e"
      },
      "source": [
        "## Best Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJYQS-gUoAT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_names = list(models.keys())\n",
        "accuracy = list(map(float, models.values()))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=model_names, y=accuracy, palette=\"viridis\")\n",
        "\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aZkPTi3rlzP"
      },
      "source": [
        "From above, we can see that **Random Forest** performed the best, closely followed by **Decision Tree** and **Neural Networks**. So we will be choosing Random Forest for the final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXZ8NE5hgbd2"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrWfMFKCU7Zu"
      },
      "outputs": [],
      "source": [
        "def predict_score(batting_team, bowling_team, runs, wickets, overs, runs_last_5, wickets_last_5, model=forest):\n",
        "  prediction_array = []\n",
        "  # Batting Team\n",
        "  if batting_team == 'Chennai Super Kings':\n",
        "    prediction_array = prediction_array + [1,0,0,0,0,0,0,0]\n",
        "  elif batting_team == 'Delhi Daredevils':\n",
        "    prediction_array = prediction_array + [0,1,0,0,0,0,0,0]\n",
        "  elif batting_team == 'Kings XI Punjab':\n",
        "    prediction_array = prediction_array + [0,0,1,0,0,0,0,0]\n",
        "  elif batting_team == 'Kolkata Knight Riders':\n",
        "    prediction_array = prediction_array + [0,0,0,1,0,0,0,0]\n",
        "  elif batting_team == 'Mumbai Indians':\n",
        "    prediction_array = prediction_array + [0,0,0,0,1,0,0,0]\n",
        "  elif batting_team == 'Rajasthan Royals':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,1,0,0]\n",
        "  elif batting_team == 'Royal Challengers Bangalore':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,0,1,0]\n",
        "  elif batting_team == 'Sunrisers Hyderabad':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,0,0,1]\n",
        "  # Bowling Team\n",
        "  if bowling_team == 'Chennai Super Kings':\n",
        "    prediction_array = prediction_array + [1,0,0,0,0,0,0,0]\n",
        "  elif bowling_team == 'Delhi Daredevils':\n",
        "    prediction_array = prediction_array + [0,1,0,0,0,0,0,0]\n",
        "  elif bowling_team == 'Kings XI Punjab':\n",
        "    prediction_array = prediction_array + [0,0,1,0,0,0,0,0]\n",
        "  elif bowling_team == 'Kolkata Knight Riders':\n",
        "    prediction_array = prediction_array + [0,0,0,1,0,0,0,0]\n",
        "  elif bowling_team == 'Mumbai Indians':\n",
        "    prediction_array = prediction_array + [0,0,0,0,1,0,0,0]\n",
        "  elif bowling_team == 'Rajasthan Royals':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,1,0,0]\n",
        "  elif bowling_team == 'Royal Challengers Bangalore':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,0,1,0]\n",
        "  elif bowling_team == 'Sunrisers Hyderabad':\n",
        "    prediction_array = prediction_array + [0,0,0,0,0,0,0,1]\n",
        "  prediction_array = prediction_array + [runs, wickets, overs, runs_last_5, wickets_last_5]\n",
        "  prediction_array = np.array([prediction_array])\n",
        "  pred = model.predict(prediction_array)\n",
        "  return int(round(pred[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY2cbaHfgdrV"
      },
      "source": [
        "### Test 1\n",
        "- Batting Team : **Delhi Daredevils**\n",
        "- Bowling Team : **Chennai Super Kings**\n",
        "- Final Score : **147/9**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3xhyRdYW4f6"
      },
      "outputs": [],
      "source": [
        "batting_team='Delhi Daredevils'\n",
        "bowling_team='Chennai Super Kings'\n",
        "score = predict_score(batting_team, bowling_team, overs=10.2, runs=68, wickets=3, runs_last_5=29, wickets_last_5=1)\n",
        "print(f'Predicted Score : {score} || Actual Score : 147')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsKOgxEZhFVO"
      },
      "source": [
        "### Test 2\n",
        "- Batting Team : **Mumbai Indians**\n",
        "- Bowling Team : **Kings XI Punjab**\n",
        "- Final Score : **176/7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWA1KTdpX9Za"
      },
      "outputs": [],
      "source": [
        "batting_team='Mumbai Indians'\n",
        "bowling_team='Kings XI Punjab'\n",
        "score = predict_score(batting_team, bowling_team, overs=12.3, runs=113, wickets=2, runs_last_5=55, wickets_last_5=0)\n",
        "print(f'Predicted Score : {score} || Actual Score : 176')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzKmW6BchwKW"
      },
      "source": [
        "### Live* Test 1 (2020 season)\n",
        "- Batting Team : **Kings XI Punjab**\n",
        "- Bowling Team : **Rajasthan Royals**\n",
        "- Final Score : **185/4**\n",
        "<br/>\n",
        "These Test Was done before the match and final score were added later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80NScDvNYZ2K"
      },
      "outputs": [],
      "source": [
        "# Live Test\n",
        "batting_team=\"Kings XI Punjab\"\n",
        "bowling_team=\"Rajasthan Royals\"\n",
        "score = predict_score(batting_team, bowling_team, overs=14.0, runs=118, wickets=1, runs_last_5=45, wickets_last_5=0)\n",
        "print(f'Predicted Score : {score} || Actual Score : 185')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta72D9zFiCd1"
      },
      "source": [
        "### Live Test 2 (2020 Season)\n",
        "- Batting Team : **Kolkata Knight Riders**\n",
        "- Bowling Team : **Chennai Super Kings**\n",
        "- Final Score : **172/5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ6dHS_YaQJ9"
      },
      "outputs": [],
      "source": [
        "# Live Test\n",
        "batting_team=\"Kolkata Knight Riders\"\n",
        "bowling_team=\"Chennai Super Kings\"\n",
        "score = predict_score(batting_team, bowling_team, overs=18.0, runs=150, wickets=4, runs_last_5=57, wickets_last_5=1)\n",
        "print(f'Predicted Score : {score} || Actual Score : 172')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKwPjoaDzgKf"
      },
      "source": [
        "### Live Test 3 (2020 Season)\n",
        "- Batting Team : **Delhi Daredevils**\n",
        "- Bowling Team : **Mumbai Indians**\n",
        "- Final Score : **110/7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdghw3mhzv0b"
      },
      "outputs": [],
      "source": [
        "batting_team='Delhi Daredevils'\n",
        "bowling_team='Mumbai Indians'\n",
        "score = predict_score(batting_team, bowling_team, overs=18.0, runs=96, wickets=8, runs_last_5=18, wickets_last_5=4)\n",
        "print(f'Predicted Score : {score} || Actual Score : 110')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkIDqCkg0DWM"
      },
      "source": [
        "### Live Test 4 (2020 Season)\n",
        "- Batting Team : **Kings XI Punjab**\n",
        "- Bowling Team : **Chennai Super Kings**\n",
        "- Final Score : **153/9**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAcEBGuw0ck8"
      },
      "outputs": [],
      "source": [
        "batting_team='Kings XI Punjab'\n",
        "bowling_team='Chennai Super Kings'\n",
        "score = predict_score(batting_team, bowling_team, overs=18.0, runs=129, wickets=6, runs_last_5=34, wickets_last_5=2)\n",
        "print(f'Predicted Score : {score} || Actual Score : 153')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UReOWOeQiSD-"
      },
      "source": [
        "# Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8q6lNENfWlY"
      },
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "\n",
        "dump(forest, \"forest_model.pkl\")\n",
        "dump(tree, \"tree_model.pkl\")\n",
        "dump(neural_net, \"neural_nets_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzjKpBWh03z_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}